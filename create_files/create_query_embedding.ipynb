{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e506d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# ✅ التحقق من GPU\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\Desktop\\IR\\ir_v5\\venv\\Lib\\site-packages\\sentence_transformers\\__init__.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     11\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     12\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     15\u001b[39m     CrossEncoder,\n\u001b[32m     16\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     17\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\Desktop\\IR\\ir_v5\\venv\\Lib\\site-packages\\sentence_transformers\\backend.py:11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Callable, Literal\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m disable_datasets_caching, is_datasets_available\n\u001b[32m     13\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\Desktop\\IR\\ir_v5\\venv\\Lib\\site-packages\\sentence_transformers\\util.py:17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hf_hub_download, snapshot_download\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor, device\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\Desktop\\IR\\ir_v5\\venv\\Lib\\site-packages\\torch\\__init__.py:2486\u001b[39m\n\u001b[32m   2482\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vmap \u001b[38;5;28;01mas\u001b[39;00m vmap\n\u001b[32m   2485\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[32m-> \u001b[39m\u001b[32m2486\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations\n\u001b[32m   2488\u001b[39m \u001b[38;5;66;03m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[32m   2489\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mTORCH_CUDA_SANITIZER\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os.environ:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\Desktop\\IR\\ir_v5\\venv\\Lib\\site-packages\\torch\\_meta_registrations.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_prims_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SymBool, SymFloat, Tensor\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_decomp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     _add_op_to_registry,\n\u001b[32m     12\u001b[39m     _convert_out_params,\n\u001b[32m     13\u001b[39m     global_decomposition_table,\n\u001b[32m     14\u001b[39m     meta_table,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpOverload\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_prims\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _prim_elementwise_meta, ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\Desktop\\IR\\ir_v5\\venv\\Lib\\site-packages\\torch\\_decomp\\__init__.py:249\u001b[39m\n\u001b[32m    245\u001b[39m             decompositions.pop(op, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# populate the table\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_decomp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecompositions\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_refs\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# See NOTE [Core ATen Ops]\u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    255\u001b[39m \u001b[38;5;66;03m# list was copied from torch/_inductor/decomposition.py\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[38;5;66;03m# excluding decompositions that results in prim ops\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[38;5;66;03m# Resulting opset of decomposition is core aten ops\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\Desktop\\IR\\ir_v5\\venv\\Lib\\site-packages\\torch\\_decomp\\decompositions.py:15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_meta_registrations\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_prims\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mprims\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_prims_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\Desktop\\IR\\ir_v5\\venv\\Lib\\site-packages\\torch\\_prims\\__init__.py:3060\u001b[39m\n\u001b[32m   3052\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch._fft_c2r(\u001b[38;5;28minput\u001b[39m, dim, normalization, last_dim_size)\n\u001b[32m   3055\u001b[39m _fft_c2r_doc = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m   3056\u001b[39m \u001b[33m    Performs a complex to real Inverse Fast Fourier Transform\u001b[39m\n\u001b[32m   3057\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m3060\u001b[39m fft_c2r = \u001b[43m_make_prim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3061\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfft_c2r(Tensor self, *, int[] dim, SymInt last_dim_size) -> Tensor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3062\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_fft_c2r_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3063\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimpl_aten\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_fft_c2r_aten\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRETURN_TYPE\u001b[49m\u001b[43m.\u001b[49m\u001b[43mNEW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3065\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_fft_c2r_doc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3066\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_frexp_meta\u001b[39m(\u001b[38;5;28mself\u001b[39m: TensorLikeType) -> Tuple[TensorLikeType, TensorLikeType]:\n\u001b[32m   3070\u001b[39m     torch._check(\n\u001b[32m   3071\u001b[39m         \u001b[38;5;28mself\u001b[39m.dtype.is_floating_point,\n\u001b[32m   3072\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[33m\"\u001b[39m\u001b[33mtorch.frexp() only supports floating-point dtypes\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3073\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\Desktop\\IR\\ir_v5\\venv\\Lib\\site-packages\\torch\\_prims\\__init__.py:319\u001b[39m, in \u001b[36m_make_prim\u001b[39m\u001b[34m(schema, return_type, meta, impl_aten, doc, tags, use_old_custom_ops_api, register_conj_neg_fallthrough)\u001b[39m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m arg.alias_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m arg.alias_info.is_write:\n\u001b[32m    318\u001b[39m         mutates_args.append(arg.name)\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m prim_def = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlibrary\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcustom_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprims::\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_prim_impl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmutates_args\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmutates_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m prim_def.register_fake(meta)\n\u001b[32m    327\u001b[39m \u001b[38;5;66;03m# all view ops get conj/neg fallthroughs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\Desktop\\IR\\ir_v5\\venv\\Lib\\site-packages\\torch\\_library\\custom_ops.py:157\u001b[39m, in \u001b[36mcustom_op\u001b[39m\u001b[34m(name, fn, mutates_args, device_types, schema)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\Desktop\\IR\\ir_v5\\venv\\Lib\\site-packages\\torch\\_library\\custom_ops.py:138\u001b[39m, in \u001b[36mcustom_op.<locals>.inner\u001b[39m\u001b[34m(fn)\u001b[39m\n\u001b[32m    135\u001b[39m     schema_str = schema\n\u001b[32m    137\u001b[39m namespace, opname = name.split(\u001b[33m\"\u001b[39m\u001b[33m::\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m result = \u001b[43mCustomOpDef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# Check that schema's alias annotations match those of `mutates_args`.\u001b[39;00m\n\u001b[32m    141\u001b[39m     expected = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\Desktop\\IR\\ir_v5\\venv\\Lib\\site-packages\\torch\\_library\\custom_ops.py:185\u001b[39m, in \u001b[36mCustomOpDef.__init__\u001b[39m\u001b[34m(self, namespace, name, schema, fn)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m._torch_dispatch_fns: Dict[\u001b[38;5;28mtype\u001b[39m, Callable] = {}\n\u001b[32m    183\u001b[39m \u001b[38;5;28mself\u001b[39m._vmap_fn: Optional[Callable] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28mself\u001b[39m._lib = \u001b[43mget_library_allowing_overwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_namespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;28mself\u001b[39m._register_to_dispatcher()\n\u001b[32m    187\u001b[39m \u001b[38;5;28mself\u001b[39m._disabled_kernel: Set = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\Desktop\\IR\\ir_v5\\venv\\Lib\\site-packages\\torch\\_library\\custom_ops.py:805\u001b[39m, in \u001b[36mget_library_allowing_overwrite\u001b[39m\u001b[34m(namespace, name)\u001b[39m\n\u001b[32m    802\u001b[39m     OPDEF_TO_LIB[qualname]._destroy()\n\u001b[32m    803\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m OPDEF_TO_LIB[qualname]\n\u001b[32m--> \u001b[39m\u001b[32m805\u001b[39m lib = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlibrary\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFRAGMENT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: TOR901\u001b[39;00m\n\u001b[32m    806\u001b[39m OPDEF_TO_LIB[qualname] = lib\n\u001b[32m    807\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m lib\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\Desktop\\IR\\ir_v5\\venv\\Lib\\site-packages\\torch\\library.py:85\u001b[39m, in \u001b[36mLibrary.__init__\u001b[39m\u001b[34m(self, ns, kind, dispatch_key)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ns \u001b[38;5;129;01min\u001b[39;00m _reserved_namespaces \u001b[38;5;129;01mand\u001b[39;00m (kind == \u001b[33m\"\u001b[39m\u001b[33mDEF\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m kind == \u001b[33m\"\u001b[39m\u001b[33mFRAGMENT\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     81\u001b[39m         ns,\n\u001b[32m     82\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m is a reserved namespace. Please try creating a library with another name.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     83\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m frame = \u001b[43mtraceback\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     86\u001b[39m filename, lineno = frame.filename, frame.lineno\n\u001b[32m     87\u001b[39m \u001b[38;5;28mself\u001b[39m.m: Optional[Any] = torch._C._dispatch_library(\n\u001b[32m     88\u001b[39m     kind, ns, dispatch_key, filename, lineno\n\u001b[32m     89\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\traceback.py:232\u001b[39m, in \u001b[36mextract_stack\u001b[39m\u001b[34m(f, limit)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    231\u001b[39m     f = sys._getframe().f_back\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m stack = \u001b[43mStackSummary\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m stack.reverse()\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\traceback.py:395\u001b[39m, in \u001b[36mStackSummary.extract\u001b[39m\u001b[34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[39m\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f, lineno \u001b[38;5;129;01min\u001b[39;00m frame_gen:\n\u001b[32m    393\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f, (lineno, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_extract_from_extended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\traceback.py:434\u001b[39m, in \u001b[36mStackSummary._extract_from_extended_frame_gen\u001b[39m\u001b[34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[39m\n\u001b[32m    430\u001b[39m     result.append(FrameSummary(\n\u001b[32m    431\u001b[39m         filename, lineno, name, lookup_line=\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m=f_locals,\n\u001b[32m    432\u001b[39m         end_lineno=end_lineno, colno=colno, end_colno=end_colno))\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m     \u001b[43mlinecache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\linecache.py:72\u001b[39m, in \u001b[36mcheckcache\u001b[39m\u001b[34m(filename)\u001b[39m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     stat = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m     74\u001b[39m     cache.pop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# ✅ التحقق من GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"✅ GPU متوفر: {gpu_name}\")\n",
    "    if \"T4\" not in gpu_name:\n",
    "        print(\"⚠️ هذا ليس T4 GPU. قد تختلف السرعة حسب نوع البطاقة.\")\n",
    "else:\n",
    "    print(\"⚠️ لا يوجد GPU، سيتم استخدام المعالج العادي (CPU)\")\n",
    "\n",
    "# ✅ تحميل النصوص من قاعدة البيانات\n",
    "def load_documents_emb(dataset_name):\n",
    "    try:\n",
    "        db_path = os.path.join(\"data\", dataset_name, \"index.db\")\n",
    "        if not os.path.exists(db_path):\n",
    "            print(f\"❌ Database not found at {db_path}\")\n",
    "            return []\n",
    "\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT processed_text FROM queries\")\n",
    "        rows = cursor.fetchall()\n",
    "        conn.close()\n",
    "\n",
    "        documents = [row[0] for row in rows if row[0]]\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading queries: {e}\")\n",
    "        return []\n",
    "\n",
    "# ✅ إنشاء التمثيلات الشعاعية (embeddings)\n",
    "def create_query_embeddings_from_db(dataset_name, batch_size=3000):\n",
    "    try:\n",
    "        output_dir = os.path.join(\"data\", dataset_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        embeddings_file = os.path.join(output_dir, f\"query_embeddings_matrix_{dataset_name}.joblib\")\n",
    "\n",
    "        if os.path.exists(embeddings_file):\n",
    "            print(f\"✔️ Embeddings already exist for {dataset_name}. Skipping.\")\n",
    "            return\n",
    "\n",
    "        queries = load_documents_emb(dataset_name)\n",
    "        if not queries:\n",
    "            print(f\"⚠️ No processed texts found in database for {dataset_name}.\")\n",
    "            return\n",
    "\n",
    "        print(f\"🚀 Loading sentence-transformers model 'all-mpnet-base-v2' ...\")\n",
    "        model = SentenceTransformer('all-mpnet-base-v2', device=device)\n",
    "\n",
    "        embeddings = []\n",
    "\n",
    "        total_batches = (len(queries) + batch_size - 1) // batch_size\n",
    "        with tqdm(total=total_batches, desc=f\"Encoding queries for {dataset_name}\") as pbar:\n",
    "            for i in range(0, len(queries), batch_size):\n",
    "                batch = queries[i:i + batch_size]\n",
    "                batch_embeddings = model.encode(batch, convert_to_numpy=True, show_progress_bar=False)\n",
    "                embeddings.append(batch_embeddings)\n",
    "                pbar.update(1)\n",
    "\n",
    "        embeddings = np.vstack(embeddings).astype(np.float32)\n",
    "\n",
    "        joblib.dump(embeddings, embeddings_file)\n",
    "        print(f\"✅ Embeddings saved to {embeddings_file}, shape = {embeddings.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "\n",
    "# ✅ التشغيل\n",
    "if __name__ == \"__main__\":\n",
    "    create_query_embeddings_from_db(\"antique\")\n",
    "    # create_query_embeddings_from_db(\"beir\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e1ab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 تحميل نموذج 'all-mpnet-base-v2' من sentence-transformers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ترميز الاستعلامات لـ antique: 100%|██████████| 1/1 [00:06<00:00,  6.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم حفظ التضمينات: (176, 768)\n",
      "📁 المسار: data\\antique\\query_embeddings_matrix_antique.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def load_documents_emb(dataset_name):\n",
    "    try:\n",
    "        db_path = os.path.join(\"data\", dataset_name, \"index.db\")\n",
    "        if not os.path.exists(db_path):\n",
    "            print(f\"❌ قاعدة البيانات غير موجودة في المسار: {db_path}\")\n",
    "            return []\n",
    "\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT processed_text FROM queries\")\n",
    "        rows = cursor.fetchall()\n",
    "        conn.close()\n",
    "\n",
    "        documents = [row[0] for row in rows if row[0]]\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        print(f\"❌ خطأ في تحميل الاستعلامات: {e}\")\n",
    "        return []\n",
    "\n",
    "def create_query_embeddings_from_db(dataset_name, batch_size=3000):\n",
    "    try:\n",
    "        output_dir = os.path.join(\"data\", dataset_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        embeddings_file = os.path.join(output_dir, f\"query_embeddings_matrix_{dataset_name}.joblib\")\n",
    "\n",
    "        if os.path.exists(embeddings_file):\n",
    "            print(f\"✔️ ملف التضمينات موجود بالفعل لـ {dataset_name}. يتم التجاوز.\")\n",
    "            return\n",
    "\n",
    "        queries = load_documents_emb(dataset_name)\n",
    "        if not queries:\n",
    "            print(f\"⚠️ لا توجد استعلامات معالجة في قاعدة البيانات لـ {dataset_name}.\")\n",
    "            return\n",
    "\n",
    "        print(f\"🚀 تحميل نموذج 'all-mpnet-base-v2' من sentence-transformers ...\")\n",
    "        model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "        embeddings = []\n",
    "\n",
    "        total_batches = (len(queries) + batch_size - 1) // batch_size\n",
    "        with tqdm(total=total_batches, desc=f\"ترميز الاستعلامات لـ {dataset_name}\") as pbar:\n",
    "            for i in range(0, len(queries), batch_size):\n",
    "                batch = queries[i:i + batch_size]\n",
    "                batch_embeddings = model.encode(batch, convert_to_numpy=True, show_progress_bar=False)\n",
    "                embeddings.append(batch_embeddings)\n",
    "                pbar.update(1)\n",
    "\n",
    "        embeddings = np.vstack(embeddings).astype(np.float32)\n",
    "        joblib.dump(embeddings, embeddings_file)\n",
    "\n",
    "        print(f\"✅ تم حفظ التضمينات: {embeddings.shape}\")\n",
    "        print(f\"📁 المسار: {embeddings_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ خطأ أثناء التضمين: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_query_embeddings_from_db(\"antique\")\n",
    "    # create_query_embeddings_from_db(\"beir\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "687df5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 تحميل نموذج 'all-mpnet-base-v2' من sentence-transformers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ترميز الاستعلامات المحسنة: 100%|██████████| 4/4 [00:18<00:00,  4.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم حفظ التضمينات: (9997, 768)\n",
      "📁 المسار: data\\beir\\embedding_enhanced_queries_beir_matrix.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def create_embeddings_from_csv(csv_path, output_file, batch_size=3000):\n",
    "    try:\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"❌ ملف CSV غير موجود: {csv_path}\")\n",
    "            return\n",
    "\n",
    "        # تحميل الملف وقراءة العمود المطلوب\n",
    "        df = pd.read_csv(csv_path)\n",
    "        queries = df['processed_query'].dropna().tolist()\n",
    "\n",
    "        if not queries:\n",
    "            print(\"⚠️ لا توجد استعلامات معالجة في الملف.\")\n",
    "            return\n",
    "\n",
    "        print(f\"🚀 تحميل نموذج 'all-mpnet-base-v2' من sentence-transformers ...\")\n",
    "        model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "        embeddings = []\n",
    "        total_batches = (len(queries) + batch_size - 1) // batch_size\n",
    "\n",
    "        with tqdm(total=total_batches, desc=\"ترميز الاستعلامات المحسنة\") as pbar:\n",
    "            for i in range(0, len(queries), batch_size):\n",
    "                batch = queries[i:i + batch_size]\n",
    "                batch_embeddings = model.encode(batch, convert_to_numpy=True, show_progress_bar=False)\n",
    "                embeddings.append(batch_embeddings)\n",
    "                pbar.update(1)\n",
    "\n",
    "        embeddings = np.vstack(embeddings).astype(np.float32)\n",
    "        joblib.dump(embeddings, output_file)\n",
    "\n",
    "        print(f\"✅ تم حفظ التضمينات: {embeddings.shape}\")\n",
    "        print(f\"📁 المسار: {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ خطأ أثناء التضمين: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file = os.path.join(\"data\", \"beir\", \"enhanced_queries_beir.csv\")\n",
    "    output_joblib = os.path.join(\"data\", \"beir\", \"embedding_enhanced_queries_beir_matrix.joblib\")\n",
    "    create_embeddings_from_csv(csv_file, output_joblib)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
