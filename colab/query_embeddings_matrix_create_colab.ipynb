{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjZGwzDDU8Nw",
        "outputId": "377e0e65-3cca-41a7-d703-6616305ff9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m798.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Uninstall conflicting packages and clear cache\n",
        "!pip uninstall -y torch torchvision torchaudio sentence-transformers -q\n",
        "!pip cache purge -q\n",
        "\n",
        "# Install compatible versions quietly\n",
        "!pip install torch==2.3.0 torchvision==0.18.0 sentence-transformers==2.7.0 pandas numpy joblib nltk tqdm -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers"
      ],
      "metadata": {
        "id": "rBQfz3_EVMtT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "import joblib\n",
        "import ast\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "from google.colab import drive, files"
      ],
      "metadata": {
        "id": "gAxAr0ulVFrR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ تحميل المجلد من Google Drive (الرابط المشترك)\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "folder_id = \"1Y19Gai5PCohj8Y4ny-gGHoXGIm0d7WJm\"\n",
        "drive_path = \"/content/data\"\n",
        "\n",
        "try:\n",
        "    gdown.download_folder(f\"https://drive.google.com/drive/folders/{folder_id}\", output=drive_path, quiet=False, use_cookies=False)\n",
        "    print(f\"✅ تم تحميل المجلد إلى: {drive_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ فشل تحميل المجلد: {str(e)}\")\n",
        "    print(\"⚠️ يرجى تحميل المجلد يدويًا إلى '/content/data' من الرابط:\")\n",
        "    print(f\"https://drive.google.com/drive/folders/{folder_id}\")\n",
        "    print(\"تأكد من أن إعدادات المشاركة مضبوطة على 'أي شخص لديه الرابط'.\")\n",
        "\n",
        "# ✅ التحقق من وجود المجلد\n",
        "if not os.path.exists(drive_path):\n",
        "    raise FileNotFoundError(f\"❌ المجلد {drive_path} غير موجود! يرجى تحميل المجلد يدويًا.\")\n",
        "def load_model_from_disk(model_path):\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"❌ Model not found at {model_path}\")\n",
        "    model = joblib.load(model_path)\n",
        "    return model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2WAGHcLWR1w",
        "outputId": "3b452338-f0b7-4b33-de71-3f9a8d01e66b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder 1spa22az_DEwyAzVMIqLpuFJc4spuGLCC beir\n",
            "Processing file 1A9He8Q8FLIJlHG2ORHG_b_v_Mr9tCAqa docs_beir.csv\n",
            "Processing file 1rhxL6LdKf285-hLejyBW39rbo352VDKW tfidf_vectorizer.joblib\n",
            "Processing file 1-UwhnEFv5_V8OYCK_y5gyptMUhGIfQvx tfidf_matrix.joblib\n",
            "Processing file 1BhBq-cWhLpB2aD_53iI2_i9w5yPhx0yU embeddings_matrix.joblib\n",
            "Processing file 1aK10vNCsxMNzyzG8pV0nCZC8XCxXPKBE embeddings_vectorizer.joblib\n",
            "Processing file 1DXw8lTPZtgvd004QQ1_uoSj1nsOIxXbg index.db\n",
            "Processing file 1INxpEXjBbsK1H3A1EEwLKjNV8h9xLmN7 embedding_index.faiss\n",
            "Processing file 1mev6-ubiKtv57J65mMQNk0F-9PcevEvC read.py\n",
            "Processing file 16no_52oaijTaZ-vYXTFu-drXSE3elmW- query_embeddings.joblib\n",
            "Retrieving folder 10Fo7nrz8eer8IXevmePhDLyO5NHX8DgK tdidf\n",
            "Retrieving folder 11RVmsWjqdEyLnSSKP-YtZx28xpDkY6S- logs\n",
            "Processing file 1jJytQfMGJ03DEsHBJRZkbAXOinHFrFq9 qrels_beir.csv\n",
            "Processing file 1Pw1enxt_y34M9GlOK0IavJQO1BCgY_kl queries_beir.csv\n",
            "Processing file 1IcxToEug6vZcfvJ78OXJuIOF9ZLXr6ZO query_enhancement_log.txt\n",
            "Processing file 1Xh3B2Hkpyjvk_s1cttPcHxAcGd2iyLF9 doc_id_mapping.joblib\n",
            "Retrieving folder 1wYN3g7t8PSWm4LcZeq5W6J3zesI2WSZX antique\n",
            "Processing file 1Txlz1nxyR8AwkDwMgBtBymMTvFgyWyOV docs_antique.csv\n",
            "Processing file 1JGbtKe87zCXT3kymly_URuSonG4P7QMX tfidf_matrix.joblib\n",
            "Processing file 1cdpLRWB_mP8AkdhnajUhA2_IlVVjwl2W embeddings_matrix.joblib\n",
            "Processing file 1WvjaJEGgAz4bB1bqkUMenQH-ISZZ_YTv embeddings_vectorizer.joblib\n",
            "Processing file 1KppNyTl-06ZVF9BYGrfHOfphH8dHd_kw embedding_index.faiss\n",
            "Processing file 1m168ne8p049qOPrurWIntNu4nyocID2I index.db\n",
            "Retrieving folder 1Sw3oWsItL5S9sx4Fk7Z2kflYnHVv6p_7 tfidf\n",
            "Retrieving folder 12vUDb_w60AQTRSi-EklbQzasw_W0mzu- logs\n",
            "Processing file 1p57TfQy_aWkcSLSlL7FsKPTG8gKslxeT query_embeddings.joblib\n",
            "Processing file 1U_OPYmDq0w1GLCnOSxYuPnU7nlChVwH6 queries_antique.csv\n",
            "Processing file 1_baTh3Yko_YUfNx4Q-w8KtmgElPZySnQ read.py\n",
            "Processing file 19wRo_0iHxPMtXtlJ2yHM8hhdd89uJiq4 qrels_antique.csv\n",
            "Processing file 1RmehJ34s6lZDJT2unQn0unnGLJsR_QHj tfidf_vectorizer.joblib\n",
            "Processing file 1z_lNnXe6l_Jek2mHjVo3CTSpF26ZVDkU query_enhancement_log.txt\n",
            "Processing file 14I2bjpIVGqTUGo4H0-HdTiiRc6Zh0cu0 enhanced_queries_antique.json\n",
            "Processing file 1NcdKblkL_oAkfqTjQCHcmmY7HQoue6zs top_10_embeddings_results_antique.json\n",
            "Processing file 1K7q-a957YqNpiuzaikCkgL21hsnVZ9DN doc_id_mapping.joblib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A9He8Q8FLIJlHG2ORHG_b_v_Mr9tCAqa\n",
            "To: /content/data/beir/docs_beir.csv\n",
            "100%|██████████| 37.3M/37.3M [00:00<00:00, 120MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rhxL6LdKf285-hLejyBW39rbo352VDKW\n",
            "To: /content/data/beir/tfidf_vectorizer.joblib\n",
            "100%|██████████| 584k/584k [00:00<00:00, 123MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-UwhnEFv5_V8OYCK_y5gyptMUhGIfQvx\n",
            "To: /content/data/beir/tfidf_matrix.joblib\n",
            "100%|██████████| 38.6M/38.6M [00:00<00:00, 162MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1BhBq-cWhLpB2aD_53iI2_i9w5yPhx0yU\n",
            "From (redirected): https://drive.google.com/uc?id=1BhBq-cWhLpB2aD_53iI2_i9w5yPhx0yU&confirm=t&uuid=cb34bbab-70e2-4e11-89de-22f1197aa5fc\n",
            "To: /content/data/beir/embeddings_matrix.joblib\n",
            "100%|██████████| 1.61G/1.61G [00:15<00:00, 102MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1aK10vNCsxMNzyzG8pV0nCZC8XCxXPKBE\n",
            "From (redirected): https://drive.google.com/uc?id=1aK10vNCsxMNzyzG8pV0nCZC8XCxXPKBE&confirm=t&uuid=777a2f90-66a3-43b9-b69e-6c82db17df35\n",
            "To: /content/data/beir/embeddings_vectorizer.joblib\n",
            "100%|██████████| 439M/439M [00:03<00:00, 135MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1DXw8lTPZtgvd004QQ1_uoSj1nsOIxXbg\n",
            "From (redirected): https://drive.google.com/uc?id=1DXw8lTPZtgvd004QQ1_uoSj1nsOIxXbg&confirm=t&uuid=a4c4c6b3-d5a3-4967-9d15-3b2bb5c13aaa\n",
            "To: /content/data/beir/index.db\n",
            "100%|██████████| 1.20G/1.20G [00:06<00:00, 174MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1INxpEXjBbsK1H3A1EEwLKjNV8h9xLmN7\n",
            "To: /content/data/beir/embedding_index.faiss\n",
            "100%|██████████| 12.2M/12.2M [00:00<00:00, 102MB/s] \n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1mev6-ubiKtv57J65mMQNk0F-9PcevEvC\n",
            "From (redirected): https://drive.google.com/uc?id=1mev6-ubiKtv57J65mMQNk0F-9PcevEvC&confirm=t&uuid=f30d82e3-8020-44a7-8a0e-2ddd8310f220\n",
            "To: /content/data/beir/read.py\n",
            "100%|██████████| 2.08k/2.08k [00:00<00:00, 3.50MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16no_52oaijTaZ-vYXTFu-drXSE3elmW-\n",
            "To: /content/data/beir/query_embeddings.joblib\n",
            "100%|██████████| 31.4M/31.4M [00:00<00:00, 88.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jJytQfMGJ03DEsHBJRZkbAXOinHFrFq9\n",
            "To: /content/data/beir/qrels_beir.csv\n",
            "100%|██████████| 256k/256k [00:00<00:00, 101MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Pw1enxt_y34M9GlOK0IavJQO1BCgY_kl\n",
            "To: /content/data/beir/queries_beir.csv\n",
            "100%|██████████| 605k/605k [00:00<00:00, 115MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IcxToEug6vZcfvJ78OXJuIOF9ZLXr6ZO\n",
            "To: /content/data/beir/query_enhancement_log.txt\n",
            "100%|██████████| 1.41M/1.41M [00:00<00:00, 140MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Xh3B2Hkpyjvk_s1cttPcHxAcGd2iyLF9\n",
            "To: /content/data/beir/doc_id_mapping.joblib\n",
            "100%|██████████| 7.08M/7.08M [00:00<00:00, 176MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Txlz1nxyR8AwkDwMgBtBymMTvFgyWyOV\n",
            "To: /content/data/antique/docs_antique.csv\n",
            "100%|██████████| 94.5M/94.5M [00:00<00:00, 141MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JGbtKe87zCXT3kymly_URuSonG4P7QMX\n",
            "To: /content/data/antique/tfidf_matrix.joblib\n",
            "100%|██████████| 86.0M/86.0M [00:00<00:00, 137MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1cdpLRWB_mP8AkdhnajUhA2_IlVVjwl2W\n",
            "From (redirected): https://drive.google.com/uc?id=1cdpLRWB_mP8AkdhnajUhA2_IlVVjwl2W&confirm=t&uuid=db633c20-f5cd-42ca-b77a-2d8dc58b33ac\n",
            "To: /content/data/antique/embeddings_matrix.joblib\n",
            "100%|██████████| 1.24G/1.24G [00:09<00:00, 125MB/s] \n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1WvjaJEGgAz4bB1bqkUMenQH-ISZZ_YTv\n",
            "From (redirected): https://drive.google.com/uc?id=1WvjaJEGgAz4bB1bqkUMenQH-ISZZ_YTv&confirm=t&uuid=199a3ed7-5fc7-4374-ac99-584f6d21aa89\n",
            "To: /content/data/antique/embeddings_vectorizer.joblib\n",
            "100%|██████████| 439M/439M [00:03<00:00, 122MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KppNyTl-06ZVF9BYGrfHOfphH8dHd_kw\n",
            "To: /content/data/antique/embedding_index.faiss\n",
            "100%|██████████| 10.3M/10.3M [00:00<00:00, 88.0MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1m168ne8p049qOPrurWIntNu4nyocID2I\n",
            "From (redirected): https://drive.google.com/uc?id=1m168ne8p049qOPrurWIntNu4nyocID2I&confirm=t&uuid=e410c6c7-5d1f-428d-88da-ecb79140a5d6\n",
            "To: /content/data/antique/index.db\n",
            "100%|██████████| 688M/688M [00:04<00:00, 151MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1p57TfQy_aWkcSLSlL7FsKPTG8gKslxeT\n",
            "To: /content/data/antique/query_embeddings.joblib\n",
            "100%|██████████| 627k/627k [00:00<00:00, 106MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1U_OPYmDq0w1GLCnOSxYuPnU7nlChVwH6\n",
            "To: /content/data/antique/queries_antique.csv\n",
            "100%|██████████| 11.7k/11.7k [00:00<00:00, 17.2MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1_baTh3Yko_YUfNx4Q-w8KtmgElPZySnQ\n",
            "From (redirected): https://drive.google.com/uc?id=1_baTh3Yko_YUfNx4Q-w8KtmgElPZySnQ&confirm=t&uuid=2d8b9b2d-a540-43ad-a673-cac9515fce48\n",
            "To: /content/data/antique/read.py\n",
            "100%|██████████| 2.09k/2.09k [00:00<00:00, 3.54MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19wRo_0iHxPMtXtlJ2yHM8hhdd89uJiq4\n",
            "To: /content/data/antique/qrels_antique.csv\n",
            "100%|██████████| 137k/137k [00:00<00:00, 65.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RmehJ34s6lZDJT2unQn0unnGLJsR_QHj\n",
            "To: /content/data/antique/tfidf_vectorizer.joblib\n",
            "100%|██████████| 575k/575k [00:00<00:00, 86.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1z_lNnXe6l_Jek2mHjVo3CTSpF26ZVDkU\n",
            "To: /content/data/antique/query_enhancement_log.txt\n",
            "100%|██████████| 375k/375k [00:00<00:00, 116MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14I2bjpIVGqTUGo4H0-HdTiiRc6Zh0cu0\n",
            "To: /content/data/antique/enhanced_queries_antique.json\n",
            "100%|██████████| 18.3k/18.3k [00:00<00:00, 31.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NcdKblkL_oAkfqTjQCHcmmY7HQoue6zs\n",
            "To: /content/data/antique/top_10_embeddings_results_antique.json\n",
            "0.00B [00:00, ?B/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1K7q-a957YqNpiuzaikCkgL21hsnVZ9DN\n",
            "To: /content/data/antique/doc_id_mapping.joblib\n",
            "100%|██████████| 6.69M/6.69M [00:00<00:00, 93.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ تم تحميل المجلد إلى: /content/data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "\n",
        "# ✅ تحقق من GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    print(f\"✅ GPU متوفر: {gpu_name}\")\n",
        "    if \"T4\" not in gpu_name:\n",
        "        print(\"⚠️ هذا ليس T4 GPU. قد تختلف السرعة حسب نوع البطاقة.\")\n",
        "else:\n",
        "    raise RuntimeError(\"❌ لا يوجد GPU! فعّل GPU من Runtime > Change runtime type.\")\n",
        "\n",
        "\n",
        "def load_documents_emb(dataset_name):\n",
        "    try:\n",
        "        db_path = f\"/content/data/{dataset_name}/index.db\"\n",
        "        if not os.path.exists(db_path):\n",
        "            print(f\"❌ Database not found at {db_path}\")\n",
        "            return []\n",
        "\n",
        "        conn = sqlite3.connect(db_path)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT processed_text FROM queries\")\n",
        "        rows = cursor.fetchall()\n",
        "        conn.close()\n",
        "\n",
        "        documents = [row[0] for row in rows if row[0]]\n",
        "        return documents\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading queries: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def create_query_embeddings_from_db(dataset_name, batch_size=3000):\n",
        "    try:\n",
        "        output_dir = f\"/content/data/{dataset_name}\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        embeddings_file = os.path.join(output_dir, f\"query_embeddings_matrix_{dataset_name}.joblib\")\n",
        "\n",
        "        if os.path.exists(embeddings_file):\n",
        "            print(f\"✔️ Embeddings already exist for {dataset_name}. Skipping.\")\n",
        "            return\n",
        "\n",
        "        queries = load_documents_emb(dataset_name)\n",
        "        if not queries:\n",
        "            print(f\"⚠️ No processed texts found in database for {dataset_name}.\")\n",
        "            return\n",
        "\n",
        "        print(f\"🚀 Loading sentence-transformers model 'all-mpnet-base-v2' ...\")\n",
        "        model = SentenceTransformer('all-mpnet-base-v2', device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        embeddings = []\n",
        "\n",
        "        total_batches = (len(queries) + batch_size - 1) // batch_size\n",
        "        with tqdm(total=total_batches, desc=f\"Encoding queries for {dataset_name}\") as pbar:\n",
        "            for i in range(0, len(queries), batch_size):\n",
        "                batch = queries[i:i + batch_size]\n",
        "                batch_embeddings = model.encode(batch, convert_to_numpy=True, show_progress_bar=False)\n",
        "                embeddings.append(batch_embeddings)\n",
        "                pbar.update(1)\n",
        "\n",
        "        embeddings = np.vstack(embeddings).astype(np.float32)\n",
        "\n",
        "        joblib.dump(embeddings, embeddings_file)\n",
        "        print(f\"✅ Embeddings saved: {embeddings.shape}\")\n",
        "\n",
        "        # تحميل ملف embeddings فقط (vectorizer غير مستخدم)\n",
        "        from google.colab import files\n",
        "        print(\"⬇️ Downloading embeddings file...\")\n",
        "        files.download(embeddings_file)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "if __name__ == \"__main__\":\n",
        "    create_query_embeddings_from_db(\"antique\")\n",
        "    create_query_embeddings_from_db(\"beir\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "S7VYCMy-VGkw",
        "outputId": "f7f521cf-fa1e-4a02-b997-74ee15827a2a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GPU متوفر: Tesla T4\n",
            "🚀 Loading sentence-transformers model 'all-mpnet-base-v2' ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding queries for antique: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Embeddings saved: (200, 768)\n",
            "⬇️ Downloading embeddings file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_98bdc18e-aec0-4f24-a2b5-7c66ee134aaa\", \"query_embeddings_matrix_antique.joblib\", 614641)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Loading sentence-transformers model 'all-mpnet-base-v2' ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding queries for beir: 100%|██████████| 4/4 [00:16<00:00,  4.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Embeddings saved: (10000, 768)\n",
            "⬇️ Downloading embeddings file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ad22cba9-9cb3-4312-a446-3c5f18130cd4\", \"query_embeddings_matrix_beir.joblib\", 30720241)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ERmR0OJrVY4X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}